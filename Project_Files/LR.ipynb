{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                28831\n",
      "Model:                          Logit   Df Residuals:                    28803\n",
      "Method:                           MLE   Df Model:                           27\n",
      "Date:                Mon, 15 Apr 2024   Pseudo R-squ.:                 0.04185\n",
      "Time:                        19:56:51   Log-Likelihood:                -9730.6\n",
      "converged:                       True   LL-Null:                       -10156.\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.093e-161\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                             0.2029      3.046      0.067      0.947      -5.768       6.174\n",
      "age                               0.0102      0.002      4.419      0.000       0.006       0.015\n",
      "cons.price.idx                   -0.0279      0.032     -0.860      0.390      -0.092       0.036\n",
      "campaign                         -0.1323      0.011    -11.676      0.000      -0.155      -0.110\n",
      "job_blue-collar                  -0.4144      0.075     -5.543      0.000      -0.561      -0.268\n",
      "job_entrepreneur                 -0.3936      0.120     -3.269      0.001      -0.630      -0.158\n",
      "job_housemaid                    -0.2406      0.138     -1.750      0.080      -0.510       0.029\n",
      "job_management                   -0.1886      0.080     -2.351      0.019      -0.346      -0.031\n",
      "job_retired                       0.7232      0.096      7.535      0.000       0.535       0.911\n",
      "job_self-employed                -0.2715      0.112     -2.434      0.015      -0.490      -0.053\n",
      "job_services                     -0.2798      0.081     -3.450      0.001      -0.439      -0.121\n",
      "job_student                       1.0805      0.102     10.604      0.000       0.881       1.280\n",
      "job_technician                   -0.1567      0.066     -2.388      0.017      -0.285      -0.028\n",
      "job_unemployed                    0.2257      0.115      1.958      0.050      -0.000       0.452\n",
      "job_unknown                      -0.1602      0.219     -0.732      0.464      -0.589       0.269\n",
      "education_basic.6y               -0.0258      0.114     -0.227      0.820      -0.248       0.197\n",
      "education_basic.9y               -0.1188      0.089     -1.329      0.184      -0.294       0.056\n",
      "education_high.school             0.0367      0.086      0.429      0.668      -0.131       0.204\n",
      "education_illiterate              0.0608      0.974      0.062      0.950      -1.849       1.971\n",
      "education_professional.course     0.1415      0.094      1.498      0.134      -0.044       0.327\n",
      "education_university.degree       0.3377      0.085      3.971      0.000       0.171       0.504\n",
      "education_unknown                 0.1723      0.111      1.546      0.122      -0.046       0.391\n",
      "marital_married                   0.0871      0.064      1.351      0.177      -0.039       0.213\n",
      "marital_single                    0.3786      0.073      5.212      0.000       0.236       0.521\n",
      "marital_unknown                   0.0618      0.475      0.130      0.896      -0.868       0.992\n",
      "housing_unknown                   0.0074   4.19e+06   1.77e-09      1.000   -8.22e+06    8.22e+06\n",
      "housing_yes                       0.0370      0.039      0.957      0.339      -0.039       0.113\n",
      "loan_unknown                      0.0074   4.19e+06   1.77e-09      1.000   -8.22e+06    8.22e+06\n",
      "loan_yes                          0.0156      0.053      0.297      0.767      -0.088       0.119\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('Otherdata/bank-additional-full.csv', delimiter=';')\n",
    "\n",
    "# Select specific columns for the model\n",
    "selected_columns = ['age', 'job', 'education', 'marital', 'housing', 'loan', 'cons.price.idx', 'campaign', 'y']\n",
    "selected_data = data[selected_columns]\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['job', 'education', 'marital', 'housing', 'loan']  # List of categorical columns excluding 'y'\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "encoded_categorical = encoder.fit_transform(selected_data[categorical_cols]).toarray()\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "numerical_features = selected_data[['age', 'cons.price.idx', 'campaign']]  # Explicitly list numerical features\n",
    "combined_features = pd.concat([numerical_features, encoded_categorical_df], axis=1)\n",
    "\n",
    "# Prepare target variable by converting 'y' to binary\n",
    "target = selected_data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Add constant to training data for statsmodels\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Fit logistic regression model with a method that includes regularization\n",
    "model = sm.Logit(y_train, X_train_sm)\n",
    "result = model.fit(method='lbfgs', maxiter=500)  # Increased maxiter and changed method to 'lbfgs'\n",
    "\n",
    "# Print the model summary\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                28831\n",
      "Model:                          Logit   Df Residuals:                    28803\n",
      "Method:                           MLE   Df Model:                           27\n",
      "Date:                Mon, 15 Apr 2024   Pseudo R-squ.:                 0.04098\n",
      "Time:                        19:56:52   Log-Likelihood:                -9739.5\n",
      "converged:                       True   LL-Null:                       -10156.\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.233e-158\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                             0.0735      2.978      0.025      0.980      -5.763       5.910\n",
      "age                               0.0094      0.002      4.094      0.000       0.005       0.014\n",
      "cons.price.idx                   -0.0238      0.032     -0.753      0.452      -0.086       0.038\n",
      "campaign                         -0.1344      0.011    -11.841      0.000      -0.157      -0.112\n",
      "job_admin.                        0.0177      0.209      0.085      0.933      -0.392       0.427\n",
      "job_blue-collar                  -0.4099      0.212     -1.937      0.053      -0.825       0.005\n",
      "job_entrepreneur                 -0.3797      0.234     -1.621      0.105      -0.839       0.079\n",
      "job_housemaid                    -0.2165      0.241     -0.897      0.369      -0.689       0.256\n",
      "job_management                   -0.1967      0.218     -0.904      0.366      -0.623       0.230\n",
      "job_retired                       0.7828      0.219      3.581      0.000       0.354       1.211\n",
      "job_self-employed                -0.2723      0.231     -1.179      0.238      -0.725       0.180\n",
      "job_services                     -0.3066      0.217     -1.411      0.158      -0.733       0.119\n",
      "job_student                       1.1114      0.225      4.940      0.000       0.670       1.552\n",
      "job_technician                   -0.1389      0.212     -0.655      0.512      -0.554       0.277\n",
      "job_unemployed                    0.2196      0.232      0.946      0.344      -0.236       0.675\n",
      "education_basic.4y               -0.1534      0.113     -1.362      0.173      -0.374       0.067\n",
      "education_basic.6y               -0.1366      0.130     -1.048      0.295      -0.392       0.119\n",
      "education_basic.9y               -0.2443      0.109     -2.238      0.025      -0.458      -0.030\n",
      "education_high.school            -0.0861      0.099     -0.868      0.386      -0.281       0.108\n",
      "education_illiterate              0.0432      0.942      0.046      0.963      -1.803       1.889\n",
      "education_professional.course     0.0118      0.108      0.109      0.913      -0.200       0.224\n",
      "education_university.degree       0.2195      0.098      2.239      0.025       0.027       0.412\n",
      "marital_divorced                 -0.1369      0.458     -0.299      0.765      -1.035       0.761\n",
      "marital_married                  -0.0512      0.455     -0.112      0.910      -0.943       0.841\n",
      "marital_single                    0.2292      0.456      0.503      0.615      -0.664       1.122\n",
      "housing_no                        0.0048   5.45e+06   8.81e-10      1.000   -1.07e+07    1.07e+07\n",
      "housing_yes                       0.0381   5.45e+06   6.99e-09      1.000   -1.07e+07    1.07e+07\n",
      "loan_no                           0.0154   5.45e+06   2.83e-09      1.000   -1.07e+07    1.07e+07\n",
      "loan_yes                          0.0275   5.45e+06   5.04e-09      1.000   -1.07e+07    1.07e+07\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('Otherdata/bank-additional-full.csv', delimiter=';')\n",
    "\n",
    "# Select specific columns for the model\n",
    "selected_columns = ['age', 'job', 'education', 'marital', 'housing', 'loan', 'cons.price.idx', 'campaign', 'y']\n",
    "selected_data = data[selected_columns]\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['job', 'education', 'marital', 'housing', 'loan']  # List of categorical columns excluding 'y'\n",
    "encoder = OneHotEncoder()\n",
    "encoded_categorical = encoder.fit_transform(selected_data[categorical_cols]).toarray()\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "numerical_features = selected_data[['age', 'cons.price.idx', 'campaign']]  # Explicitly list numerical features\n",
    "combined_features = pd.concat([numerical_features, encoded_categorical_df], axis=1)\n",
    "\n",
    "combined_features = combined_features.drop(['housing_unknown', 'loan_unknown', 'job_unknown', 'education_unknown', 'marital_unknown'], axis=1).astype(int) # Drop unknown columns\n",
    "\n",
    "# Prepare target variable by converting 'y' to binary\n",
    "target = selected_data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Add constant to training data for statsmodels\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Fit logistic regression model with a method that includes regularization\n",
    "model = sm.Logit(y_train, X_train_sm)\n",
    "result = model.fit(method='lbfgs', maxiter=500)  # Increased maxiter and changed method to 'lbfgs'\n",
    "\n",
    "# Print the model summary\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
